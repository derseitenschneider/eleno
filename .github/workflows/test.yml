name: 🧪 Legacy Test Suite (DISABLED)

on:
  # DISABLED: Replaced by streamlined workflows
  # - test-and-deploy-dev.yml (runs on dev pushes)  
  # - deploy-production.yml (runs on main pushes)
  # - test-comprehensive.yml (runs nightly)
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  NODE_VERSION: "22"
  CACHE_VERSION: "v1"

jobs:
  # Job 1: Unit Tests with Vitest
  unit-tests:
    name: 🧪 Unit Tests (Vitest)
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./app
    outputs:
      cache-key: ${{ steps.cache-deps.outputs.cache-hit }}
    
    steps:
      - name: 🚚 Checkout code
        uses: actions/checkout@v4

      - name: 📦 Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: app/package-lock.json

      - name: 💾 Cache node modules
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: app/node_modules
          key: ${{ runner.os }}-node-${{ env.CACHE_VERSION }}-${{ hashFiles('app/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-node-

      - name: 📥 Install dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: npm ci

      - name: 🔧 Type check
        run: npm run typecheck

      - name: 🧪 Run unit tests with coverage
        run: npm run test:cov

      - name: 🎯 Check coverage thresholds
        id: coverage-check
        run: node scripts/check-coverage-thresholds.js
        continue-on-error: true
        
      - name: 📊 Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report-${{ github.run_id }}
          path: |
            app/coverage/
            !app/coverage/**/*.tmp
          retention-days: 30


      - name: 📊 Generate coverage summary
        if: always()
        run: |
          if [ -f coverage/coverage-summary.json ]; then
            node scripts/generate-test-summary.js coverage > coverage-data.json
            echo "COVERAGE_DATA<<EOF" >> $GITHUB_ENV
            cat coverage-data.json >> $GITHUB_ENV
            echo "EOF" >> $GITHUB_ENV
          fi

      - name: 📋 Unit Test Summary
        if: always()
        run: |
          echo "## 🧪 Unit Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Coverage threshold status
          if [ "${{ steps.coverage-check.outcome }}" = "success" ]; then
            echo "✅ **Coverage Thresholds**: All thresholds met" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Coverage Thresholds**: Some thresholds failed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f coverage/coverage-summary.json ]; then
            node scripts/generate-test-summary.js github >> $GITHUB_STEP_SUMMARY
          else
            echo "✅ Unit tests completed" >> $GITHUB_STEP_SUMMARY
            echo "⚠️ Coverage data not available" >> $GITHUB_STEP_SUMMARY
          fi
          
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📦 Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- [Coverage Report HTML](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)" >> $GITHUB_STEP_SUMMARY

      - name: ❌ Fail build if coverage thresholds not met
        if: steps.coverage-check.outcome == 'failure'
        run: |
          echo "::error title=Coverage Thresholds Failed::Build failed due to insufficient test coverage. See coverage report for details."
          exit 1

  # Job 2: Build Tests (both staging and production)
  build-tests:
    name: 🔨 Build Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    strategy:
      matrix:
        build-mode: [staging, production]
    defaults:
      run:
        working-directory: ./app
    
    steps:
      - name: 🚚 Checkout code
        uses: actions/checkout@v4

      - name: 📦 Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: app/package-lock.json

      - name: 💾 Restore node modules cache
        uses: actions/cache@v4
        with:
          path: app/node_modules
          key: ${{ runner.os }}-node-${{ env.CACHE_VERSION }}-${{ hashFiles('app/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-node-

      - name: 📥 Install dependencies
        run: npm ci

      - name: 🔨 Build for ${{ matrix.build-mode }}
        run: |
          if [ "${{ matrix.build-mode }}" = "staging" ]; then
            npm run build:staging
          else
            npm run build
          fi

      - name: 💾 Cache build artifacts
        uses: actions/cache@v4
        with:
          path: app/dist
          key: ${{ runner.os }}-build-${{ matrix.build-mode }}-${{ github.sha }}

      - name: 📋 Build Summary
        run: |
          echo "## 🔨 Build Test Results (${{ matrix.build-mode }})" >> $GITHUB_STEP_SUMMARY
          echo "✅ ${{ matrix.build-mode }} build completed successfully" >> $GITHUB_STEP_SUMMARY
          echo "📦 Build size: $(du -sh dist | cut -f1)" >> $GITHUB_STEP_SUMMARY

  # Job 3: E2E Tests with Playwright
  e2e-tests:
    name: 🎭 E2E Tests (Playwright)
    runs-on: ubuntu-latest
    needs: [unit-tests, build-tests]
    defaults:
      run:
        working-directory: ./app
    environment:
      name: tests.e2e
    env:
      # Environment variables for E2E tests
      VITE_ENV: ${{ secrets.VITE_ENV || 'staging' }}
      VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
      VITE_SUPABASE_KEY: ${{ secrets.VITE_SUPABASE_KEY }}
      VITE_STRIPE_PUBLISHABLE_KEY: ${{ secrets.VITE_STRIPE_PUBLISHABLE_KEY }}
      VITE_API_URL: ${{ secrets.VITE_API_URL }}
      VITE_STRIPE_PRICE_ID_MONTHLY: ${{ secrets.VITE_STRIPE_PRICE_ID_MONTHLY }}
      VITE_STRIPE_PRICE_ID_YEARLY: ${{ secrets.VITE_STRIPE_PRICE_ID_YEARLY }}
      VITE_STRIPE_PRICE_ID_LIFETIME: ${{ secrets.VITE_STRIPE_PRICE_ID_LIFETIME }}
    
    strategy:
      fail-fast: false
      matrix:
        project: 
          - "visual-regression"
          # - "accessibility"  # Temporarily disabled - accessibility tests not ready for production
          - "performance"
          - "edge-case"
        exclude:
          # Exclude cross-browser tests from regular E2E run (they have their own workflow)
          - project: "cross-browser"
        
    steps:
      - name: 🚚 Checkout code
        uses: actions/checkout@v4

      - name: 📦 Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: app/package-lock.json

      - name: 💾 Restore node modules cache
        uses: actions/cache@v4
        with:
          path: app/node_modules
          key: ${{ runner.os }}-node-${{ env.CACHE_VERSION }}-${{ hashFiles('app/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-node-

      - name: 📥 Install dependencies
        run: npm ci

      - name: 💾 Cache Playwright browsers
        id: playwright-cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ env.CACHE_VERSION }}-${{ hashFiles('app/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-playwright-

      - name: 📥 Install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: npx playwright install --with-deps chromium

      - name: 📥 Install Playwright dependencies only
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        run: npx playwright install-deps chromium

      - name: 🎭 Run E2E tests for ${{ matrix.project }}
        id: e2e-tests
        run: npm run pw -- --project='*${{ matrix.project }}*'
        continue-on-error: true
        timeout-minutes: 30

      - name: 📊 Generate test report
        if: always()
        run: |
          if [ -f test-results/results.json ]; then
            node scripts/generate-test-summary.js playwright > playwright-data-${{ matrix.project }}.json
          fi

      - name: 📤 Upload Playwright report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report-${{ matrix.project }}-${{ github.run_id }}
          path: |
            app/playwright-report/
            app/playwright-data-${{ matrix.project }}.json
          retention-days: 30

      - name: 📤 Upload test results with traces
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.project }}-${{ github.run_id }}
          path: |
            app/test-results/
            !app/test-results/**/*.webm
          retention-days: 30

      - name: 📤 Upload failure artifacts
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: failure-artifacts-${{ matrix.project }}-${{ github.run_id }}
          path: |
            app/test-results/**/*.png
            app/test-results/**/*.webm
            app/test-results/**/trace.zip
          retention-days: 14

      - name: 📋 E2E Test Summary
        if: always()
        run: |
          echo "## 🎭 E2E Test Results (${{ matrix.project }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f test-results/results.json ]; then
            # Parse test results and show detailed summary
            node scripts/generate-test-summary.js playwright | jq -r '
              "**Test Suite**: '${{ matrix.project }}'",
              "**Total Tests**: \(.summary.total // 0)",
              "**Passed**: \(.summary.passed // 0) ✅",
              "**Failed**: \(.summary.failed // 0) ❌", 
              "**Flaky**: \(.summary.flaky // 0) ⚠️",
              "**Duration**: \((.summary.duration // 0) / 1000 | floor)s"
            ' >> $GITHUB_STEP_SUMMARY
          else
            if [ "${{ steps.e2e-tests.outcome }}" = "success" ]; then
              echo "✅ All tests passed for ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
            else
              echo "❌ Some tests failed for ${{ matrix.project }}" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📦 Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- [HTML Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)" >> $GITHUB_STEP_SUMMARY
          echo "- [Test Results & Traces](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.e2e-tests.outcome }}" != "success" ]; then
            echo "- [Failure Screenshots & Videos](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)" >> $GITHUB_STEP_SUMMARY
          fi

  # Job 4: Subscription Tests (Critical User Flows)
  subscription-tests:
    name: 💳 Subscription Flow Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, build-tests]
    defaults:
      run:
        working-directory: ./app
    environment:
      name: tests.subscriptions
    env:
      STRIPE_SECRET_KEY: ${{ secrets.STRIPE_TEST_SECRET_KEY }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      VITE_ENV: ${{ secrets.VITE_ENV }}
      VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
      VITE_SUPABASE_KEY: ${{ secrets.VITE_SUPABASE_KEY }}
      VITE_STRIPE_PUBLISHABLE_KEY: ${{ secrets.VITE_STRIPE_PUBLISHABLE_KEY }}
      VITE_API_URL: ${{ secrets.VITE_API_URL }}
      VITE_STRIPE_PRICE_ID_MONTHLY: ${{ secrets.VITE_STRIPE_PRICE_ID_MONTHLY }}
      VITE_STRIPE_PRICE_ID_YEARLY: ${{ secrets.VITE_STRIPE_PRICE_ID_YEARLY }}
      VITE_STRIPE_PRICE_ID_LIFETIME: ${{ secrets.VITE_STRIPE_PRICE_ID_LIFETIME }}
    
    steps:
      - name: 🚚 Checkout code
        uses: actions/checkout@v4

      - name: 🔧 Install Stripe CLI
        run: |
          curl -s https://packages.stripe.dev/api/security/keypair/stripe-cli-gpg/public | gpg --dearmor | sudo tee /usr/share/keyrings/stripe.gpg > /dev/null
          echo "deb [signed-by=/usr/share/keyrings/stripe.gpg] https://packages.stripe.dev/stripe-cli-debian-local stable main" | sudo tee -a /etc/apt/sources.list.d/stripe.list
          sudo apt update
          sudo apt install stripe
          stripe --version

      - name: 📦 Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: app/package-lock.json

      - name: 💾 Restore node modules cache
        uses: actions/cache@v4
        with:
          path: app/node_modules
          key: ${{ runner.os }}-node-${{ env.CACHE_VERSION }}-${{ hashFiles('app/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-node-

      - name: 📥 Install dependencies
        run: npm ci

      - name: 💾 Restore Playwright browsers cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ env.CACHE_VERSION }}-${{ hashFiles('app/package-lock.json') }}

      - name: 📥 Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: 💳 Run subscription tests
        id: subscription-tests
        run: npm run pw:subs
        timeout-minutes: 45
        continue-on-error: true

      - name: 📊 Generate subscription test report
        if: always()
        run: |
          if [ -f test-results/results.json ]; then
            node scripts/generate-test-summary.js playwright > subscription-data.json
          fi

      - name: 📤 Upload subscription test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: subscription-test-report-${{ github.run_id }}
          path: |
            app/playwright-report/
            app/subscription-data.json
          retention-days: 30

      - name: 📤 Upload subscription test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: subscription-test-results-${{ github.run_id }}
          path: app/test-results/
          retention-days: 30

      - name: 📋 Subscription Test Summary
        if: always()
        run: |
          echo "## 💳 Subscription Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f test-results/results.json ]; then
            node scripts/generate-test-summary.js playwright | jq -r '
              "**Critical User Flows**: Subscription Management",
              "**Total Tests**: \(.summary.total // 0)",
              "**Passed**: \(.summary.passed // 0) ✅",
              "**Failed**: \(.summary.failed // 0) ❌",
              "**Duration**: \((.summary.duration // 0) / 1000 | floor)s",
              "**Pass Rate**: \(.passRate // 0)%"
            ' >> $GITHUB_STEP_SUMMARY
          else
            if [ "${{ steps.subscription-tests.outcome }}" = "success" ]; then
              echo "✅ All subscription flows passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "❌ Some subscription tests failed" >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔗 Quick Links" >> $GITHUB_STEP_SUMMARY
          echo "- [HTML Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)" >> $GITHUB_STEP_SUMMARY
          echo "- [Test Results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)" >> $GITHUB_STEP_SUMMARY

  # Job 5: Test Summary and Status
  test-summary:
    name: 📊 Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, build-tests, e2e-tests, subscription-tests]
    if: always()
    defaults:
      run:
        working-directory: ./app
    
    steps:
      - name: 🚚 Checkout code
        uses: actions/checkout@v4

      - name: 📦 Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: 📥 Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts

      - name: 📊 Aggregate test results
        run: |
          # Create comprehensive test summary
          echo "# 🧪 Comprehensive Test Suite Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow Run**: [\`${{ github.run_id }}\`](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: [\`${{ github.sha }}\`](https://github.com/${{ github.repository }}/commit/${{ github.sha }})" >> $GITHUB_STEP_SUMMARY
          echo "**Branch**: \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Test Results Overview
          echo "## 📋 Test Results Overview" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status | Details |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|---------|" >> $GITHUB_STEP_SUMMARY
          
          # Unit Tests
          if [ "${{ needs.unit-tests.result }}" = "success" ]; then
            echo "| 🧪 Unit Tests | ✅ PASSED | All unit tests and type checking completed successfully |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| 🧪 Unit Tests | ❌ FAILED | Unit tests or type checking failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Build Tests
          if [ "${{ needs.build-tests.result }}" = "success" ]; then
            echo "| 🔨 Build Tests | ✅ PASSED | Both staging and production builds successful |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| 🔨 Build Tests | ❌ FAILED | Build process failed for one or more environments |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # E2E Tests
          if [ "${{ needs.e2e-tests.result }}" = "success" ]; then
            echo "| 🎭 E2E Tests | ✅ PASSED | All end-to-end test suites completed successfully |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| 🎭 E2E Tests | ⚠️ MIXED | Some E2E tests failed - check individual reports |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Subscription Tests
          if [ "${{ needs.subscription-tests.result }}" = "success" ]; then
            echo "| 💳 Subscription Tests | ✅ PASSED | All critical subscription flows working |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| 💳 Subscription Tests | ⚠️ MIXED | Some subscription tests failed |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: 📈 Coverage Summary
        run: |
          echo "## 📈 Code Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Try to find coverage data in artifacts
          if find ./artifacts -name "coverage-summary.json" -type f | head -1 | xargs test -f; then
            COVERAGE_FILE=$(find ./artifacts -name "coverage-summary.json" -type f | head -1)
            
            echo "| Metric | Coverage | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|----------|--------|" >> $GITHUB_STEP_SUMMARY
            
            # Parse coverage data with jq
            STATEMENTS=$(cat "$COVERAGE_FILE" | jq -r '.total.statements.pct')
            BRANCHES=$(cat "$COVERAGE_FILE" | jq -r '.total.branches.pct')
            FUNCTIONS=$(cat "$COVERAGE_FILE" | jq -r '.total.functions.pct')
            LINES=$(cat "$COVERAGE_FILE" | jq -r '.total.lines.pct')
            
            # Function to get status emoji
            get_status() {
              if (( $(echo "$1 >= 95" | bc -l) )); then echo "🟢 Excellent"
              elif (( $(echo "$1 >= 80" | bc -l) )); then echo "✅ Good"
              elif (( $(echo "$1 >= 70" | bc -l) )); then echo "🟡 Fair"
              else echo "🔴 Needs Work"; fi
            }
            
            echo "| Statements | ${STATEMENTS}% | $(get_status $STATEMENTS) |" >> $GITHUB_STEP_SUMMARY
            echo "| Branches | ${BRANCHES}% | $(get_status $BRANCHES) |" >> $GITHUB_STEP_SUMMARY
            echo "| Functions | ${FUNCTIONS}% | $(get_status $FUNCTIONS) |" >> $GITHUB_STEP_SUMMARY
            echo "| Lines | ${LINES}% | $(get_status $LINES) |" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ Coverage data not available" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: 📦 Artifacts Summary
        run: |
          echo "## 📦 Available Test Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 Coverage Reports" >> $GITHUB_STEP_SUMMARY
          echo "- **HTML Coverage Report**: Interactive coverage visualization" >> $GITHUB_STEP_SUMMARY
          echo "- **JSON Coverage Data**: Machine-readable coverage metrics" >> $GITHUB_STEP_SUMMARY
          echo "- **LCOV Report**: For integration with external tools" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🎭 Playwright Reports" >> $GITHUB_STEP_SUMMARY
          echo "- **HTML Test Reports**: Interactive test results with screenshots" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Traces**: Detailed execution traces for debugging" >> $GITHUB_STEP_SUMMARY
          echo "- **Failure Artifacts**: Screenshots and videos of failed tests" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔗 Quick Access Links" >> $GITHUB_STEP_SUMMARY
          echo "- [All Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Workflow Summary](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          
          # List all available artifacts
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📋 Artifact Inventory" >> $GITHUB_STEP_SUMMARY
          if [ -d "./artifacts" ]; then
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            find ./artifacts -type d -name "*${{ github.run_id }}*" | sed 's|./artifacts/||' | sort >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi

      - name: 🎯 Set overall status
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 🎯 Overall Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Determine overall status
          if [ "${{ needs.unit-tests.result }}" = "success" ] && [ "${{ needs.build-tests.result }}" = "success" ]; then
            echo "✅ **CRITICAL TESTS PASSED** - Core functionality is working" >> $GITHUB_STEP_SUMMARY
            
            # Check optional tests
            OPTIONAL_FAILURES=0
            if [ "${{ needs.e2e-tests.result }}" != "success" ]; then
              OPTIONAL_FAILURES=$((OPTIONAL_FAILURES + 1))
            fi
            if [ "${{ needs.subscription-tests.result }}" != "success" ]; then
              OPTIONAL_FAILURES=$((OPTIONAL_FAILURES + 1))
            fi
            
            if [ $OPTIONAL_FAILURES -eq 0 ]; then
              echo "🎉 **ALL TESTS PASSED** - Everything is working perfectly!" >> $GITHUB_STEP_SUMMARY
            else
              echo "⚠️ **SOME OPTIONAL TESTS FAILED** - Non-critical issues detected" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "The build is safe to deploy, but please review the failed tests." >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "❌ **CRITICAL TESTS FAILED** - Build not ready for deployment" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Please fix the failing unit tests or build issues before proceeding." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi